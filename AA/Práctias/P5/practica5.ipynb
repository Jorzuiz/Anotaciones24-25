{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main program\n",
      "If your compute_gradient implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9). \n",
      "Relative Difference: 3.70968e-11\n",
      "Test passed!\n",
      "If your compute_gradient implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9). \n",
      "Relative Difference: 3.65803e-11\n",
      "Test passed!\n",
      "We assume that: random_state of train_test_split  = 0 alpha=1, num_iterations = 2000, test_size=0.33, seed=0 and epislom = 0.12 \n",
      "Test 1 Calculando para lambda = 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MLPClassifier.__init__() takes from 1 to 3 positional arguments but 4 positional arguments (and 2 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#test.MLP_test(X_train,y_train,X_test,mlp.predict(y_test))\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMLP_test_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jorda\\OneDrive\\Documentos\\Uni\\Anotaciones24-25\\AA\\Práctias\\P5\\Practica05.py:42\u001b[0m, in \u001b[0;36mMLP_test_sklearn\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe assume that: random_state of train_test_split  = 0 alpha=1, num_iterations = 2000, test_size=0.33, seed=0 and epislom = 0.12 \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 1 Calculando para lambda = 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mSKLearn_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.92606\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 2 Calculando para lambda = 0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m SKLearn_test(X_train,y_train,X_test,y_test, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m0.92545\u001b[39m,\u001b[38;5;241m2000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jorda\\OneDrive\\Documentos\\Uni\\Anotaciones24-25\\AA\\Práctias\\P5\\Practica05.py:31\u001b[0m, in \u001b[0;36mSKLearn_test\u001b[1;34m(X_train, y_train, X_test, y_test, alpha, lambda_, num_ite, baseLineAccuracy, verbose)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSKLearn_test\u001b[39m(X_train, y_train, X_test, y_test, alpha, lambda_, num_ite, baseLineAccuracy, verbose \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 31\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m \u001b[43mMLPClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_ite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     mlp\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     34\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: MLPClassifier.__init__() takes from 1 to 3 positional arguments but 4 positional arguments (and 2 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import utils as util\n",
    "from MLP import MLP\n",
    "import Practica05 as test\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Practica 5\n",
    "# Sobre la implementación de feedforward de la práctica 4 creamos una implementación de backpropagation\n",
    "# para entrenar una red neuronal completa\n",
    "# Contará con un parámetro de regularización l2\n",
    "\n",
    "# El tamaño de cada imágen de entrada es 400 (20*20 pixeles)\n",
    "# 5000*\n",
    "X,y = util.load_data('data/ex3data1.mat')\n",
    "y = util.one_hot_encoding(y)    # Dado por Sklearn, se puede usar tambien un argmax para aplicar una máscara\n",
    "\n",
    "# Ejercicio1\n",
    "test.gradientTest()\n",
    "# Configuramos una red con capa oculta de 25 y capa de salida de 10\n",
    "mlp = MLP(400, 25, 10, 0, 0.12) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "#test.MLP_test(X_train,y_train,X_test,mlp.predict(y_test))\n",
    "\n",
    "test.MLP_test_sklearn(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
